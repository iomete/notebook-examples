{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Jupiter\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install additional library\n",
    "For example purposes we will install sparksql-magic library. This library allows us to use SQL queries in our notebook. We will need to use special syntax `%pip` and load library with `$load_ext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sparksql-magic\n",
      "  Downloading sparksql_magic-0.0.3-py36-none-any.whl (4.3 kB)\n",
      "Requirement already satisfied: ipython>=7.4.0 in /usr/lib/python3/dist-packages (from sparksql-magic) (7.20.0)\n",
      "Collecting pyspark>=2.3.0\n",
      "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=7.4.0->sparksql-magic) (4.8.0)\n",
      "Collecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824010 sha256=5c7a48b38e34d09d8602a678507830ee8793d500c850409dddadd77c9c86728d\n",
      "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark, sparksql-magic\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.2 sparksql-magic-0.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sparksql-magic\n",
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">namespace</td></tr><tr><td>default</td></tr><tr><td>demo_db</td></tr><tr><td>employees_pg_raw</td></tr><tr><td>employees_raw</td></tr><tr><td>mongo_local_db</td></tr><tr><td>mysql_tutorial</td></tr><tr><td>pg_tutorial</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "show databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">namespace</td><td style=\"font-weight: bold\">tableName</td><td style=\"font-weight: bold\">isTemporary</td></tr><tr><td>demo_db</td><td>agents</td><td>False</td></tr><tr><td>demo_db</td><td>company</td><td>False</td></tr><tr><td>demo_db</td><td>customer</td><td>False</td></tr><tr><td>demo_db</td><td>daysorder</td><td>False</td></tr><tr><td>demo_db</td><td>foods</td><td>False</td></tr><tr><td>demo_db</td><td>listofitem</td><td>False</td></tr><tr><td>demo_db</td><td>orders</td><td>False</td></tr><tr><td>demo_db</td><td>student</td><td>False</td></tr><tr><td>demo_db</td><td>studentreport</td><td>False</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "show tables in demo_db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark",
   "language": "python",
   "name": "iomete_pyspark_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
